{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgs1voPAfVN2Lt9m7RuIsh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RPGraciotti/BootCampAlura/blob/main/Projeto_final/Evaluating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I3fvVXZGc9D",
        "outputId": "90d43ef5-6ed8-4d98-8473-1b46fc535918"
      },
      "source": [
        "pip install tpot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tpot\n",
            "  Downloading TPOT-0.11.7-py3-none-any.whl (87 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 81 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 87 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.0.1)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (4.62.0)\n",
            "Collecting xgboost>=1.1.0\n",
            "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 166.7 MB 14 kB/s \n",
            "\u001b[?25hCollecting stopit>=1.1.1\n",
            "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tpot) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.19.5)\n",
            "Collecting deap>=1.2\n",
            "  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 52.5 MB/s \n",
            "\u001b[?25hCollecting update-checker>=0.16\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tpot) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11952 sha256=81b55c62cb250a0e765216b95c0f60ccb7a65b5fa747fbe65a8da157cd12a31b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/d2/79/eaf81edb391e27c87f51b8ef901ecc85a5363dc96b8b8d71e3\n",
            "Successfully built stopit\n",
            "Installing collected packages: xgboost, update-checker, stopit, deap, tpot\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.7 update-checker-0.18.0 xgboost-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sp9FWLdC0AU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3syLkDDpmyt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from tpot.builtins import StackingEstimator\n",
        "from tpot.builtins import ZeroCount\n",
        "from tpot.export_utils import set_param_recursive\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif, SelectFwe\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "import warnings"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af-LeOYS6G1C"
      },
      "source": [
        "def multi_score_cv(model, x, y, cv, model_title, set_context = \"talk\", figsize = (10, 6)):\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.simplefilter('ignore') # ignora warnings durante cross_validate\n",
        "    cv_results = cross_validate(model, x, y, \n",
        "                                cv = cv, scoring = [\"precision\", \"roc_auc\", \"recall\", \"f1\"]) # performa cross validate com parametros escolhidos e separa os scorings de itneresse\n",
        "  \n",
        "  precision = cv_results[\"test_precision\"] \n",
        "  roc_auc = cv_results[\"test_roc_auc\"]\n",
        "  recall = cv_results[\"test_recall\"]\n",
        "  f1 = cv_results[\"test_f1\"]\n",
        "  scores = pd.DataFrame(dict(Precision = precision, ROC_AUC = roc_auc, Recall = recall, F1 = f1))\n",
        "  scores_melt = scores.melt()\n",
        "\n",
        "  plt.figure(figsize = figsize)\n",
        "  sns.set_context(set_context)\n",
        "  sns.boxplot(data = scores_melt, x = \"value\", y = \"variable\", linewidth = 2.5)\n",
        "  plt.title(f\"Distribuição de valores de score por CV - Modelo {model_title}\")\n",
        "  plt.xlabel(\"\")\n",
        "  plt.xlim(-0.1, 1.1)\n",
        "  plt.ylabel(\"Métrica\")\n",
        "  plt.show()\n",
        "  sns.reset_orig()\n",
        "\n",
        "  return scores"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWQjPLhAroD3"
      },
      "source": [
        "def set_split(data):\n",
        "  \n",
        "  data = data.sample(frac = 1, random_state = 78329).reset_index(drop = True)\n",
        "  y = data.loc[:,\"ICU\"]\n",
        "  y = y.rename(\"target\")\n",
        "  x = data.drop([\"PATIENT_VISIT_IDENTIFIER\", \"ICU\", \"WINDOW\"], axis = 1)\n",
        "  split = train_test_split(x, y, stratify = y, test_size = 0.2, random_state = 78329)\n",
        "\n",
        "  return split"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0cg1ae_zHIN"
      },
      "source": [
        "# Função curva ROC-AUC de https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
        "\n",
        "def roc_auc_curve(data, model, title):\n",
        "\n",
        "  ns_probs = [0 for _ in range(len(data[3]))]\n",
        "  lr_probs = model.predict_proba(data[1])\n",
        "  lr_probs = lr_probs[:, 1]\n",
        "  ns_auc = roc_auc_score(data[3], ns_probs)\n",
        "  lr_auc = roc_auc_score(data[3], lr_probs)\n",
        "  ns_fpr, ns_tpr, _ = roc_curve(data[3], ns_probs)\n",
        "  lr_fpr, lr_tpr, _ = roc_curve(data[3], lr_probs)\n",
        "  \n",
        "  plt.plot(ns_fpr, ns_tpr, linestyle = '--', label = \"Modelo neutro\")\n",
        "  plt.plot(lr_fpr, lr_tpr, marker = \".\", label = f\"Modelo {title}\")\n",
        "  plt.xlabel(\"Taxa de falso positivo\")\n",
        "  plt.ylabel(\"Taxa de verdadeiro positivo\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn-EqBno4qQI"
      },
      "source": [
        "# Função de curva - precision recall de https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
        "\n",
        "def prec_rec_curve(data, model, title):\n",
        "  \n",
        "  lr_probs = model.predict_proba(data[1])\n",
        "  lr_probs = lr_probs[:, 1]\n",
        "  yhat = model.predict(data[1])\n",
        "  lr_precision, lr_recall, _ = precision_recall_curve(data[3], lr_probs)\n",
        "  lr_f1, lr_auc = f1_score(data[3], yhat), auc(lr_recall, lr_precision)\n",
        "  no_skill = len(data[3][data[3]==1]) / len(data[3])\n",
        "  \n",
        "  plt.plot([0, 1], [no_skill, no_skill], linestyle = '--', label = \"Modelo neutro\")\n",
        "  plt.plot(lr_recall, lr_precision, marker = '.', label = f\"Modelo {title}\")\n",
        "  plt.xlabel(\"Recall\")\n",
        "  plt.ylabel(\"Precisão\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kqXu1_msaJC"
      },
      "source": [
        "path = \"https://raw.githubusercontent.com/RPGraciotti/BootCampAlura/main/Data/data_clean_ohe.csv\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpSS_mHKpKcO"
      },
      "source": [
        "df_clean = pd.read_csv(path)\n",
        "# df_clean"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvyvtRZ6uvhc"
      },
      "source": [
        "main_split = set_split(df_clean)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xUBDO7zv_7a"
      },
      "source": [
        "x = df_clean.drop([\"PATIENT_VISIT_IDENTIFIER\", \"ICU\", \"WINDOW\"], axis = 1)\n",
        "y = df_clean.loc[:,\"ICU\"]\n",
        "y = y.rename(\"target\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYfmQSu4wmd5"
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Af11kjInoB"
      },
      "source": [
        "AVALIAÇÃO DOS MODELOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEoEw3dYSZFG"
      },
      "source": [
        "PRECISION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCU8lA-GSXwt"
      },
      "source": [
        "m1 = RandomForestClassifier(bootstrap=True, criterion=\"gini\", \n",
        "                            max_features=0.1, min_samples_leaf=15, min_samples_split=9, n_estimators=100)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irJKmPZZSXwx"
      },
      "source": [
        "m1_scores = multi_score_cv(model = m1, x = x, y = y, cv = cv,\n",
        "                           model_title = \"Precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsWu0ufgwimc"
      },
      "source": [
        "m1_eval = m1.fit(X = main_split[0], y = main_split[2])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgBuRsaoxADT"
      },
      "source": [
        "plt.figure(figsize = (10, 6))\n",
        "plot_confusion_matrix(m1_eval, X = main_split[1], y_true = main_split[3], cmap = plt.cm.PuBu, normalize = \"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7olpfbC3nPB"
      },
      "source": [
        "roc_auc_curve(data = main_split, model = m1_eval, title = \"Precision\")\n",
        "prec_rec_curve(data = main_split, model = m1_eval, title = \"Precision\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D5qF8eEAFCn"
      },
      "source": [
        "forest_importances = pd.Series(m1_eval.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pe2GQHbItg1"
      },
      "source": [
        "MODELO 2 - MAXIMIZAÇÃO DO ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tLQClQjInQ7"
      },
      "source": [
        "m1 = make_pipeline(\n",
        "    SelectPercentile(score_func=f_classif, percentile=60),\n",
        "    RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.1, min_samples_leaf=18, min_samples_split=9, n_estimators=100)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otGk67p8I1IM"
      },
      "source": [
        "m1_eval = m1.fit(main_split[0], main_split[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zVSZ6KuJ9Oz"
      },
      "source": [
        "plot_confusion_matrix(m1_eval, main_split[1], main_split[3], cmap = plt.cm.PuBu, normalize = \"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqUAbA70vTGP"
      },
      "source": [
        "ROC_AUC e PRECISION-RECALL CURVES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae4ZiEEq68qv"
      },
      "source": [
        "m1_scores = multi_score_cv(model = m1_eval, x = x, y = y, cv = cv, model_title = \"ROC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JIosYlcMGTK"
      },
      "source": [
        "RECALL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWulS-D2MPzr"
      },
      "source": [
        "m2 = make_pipeline(\n",
        "    StackingEstimator(estimator=RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.7500000000000001, \n",
        "                                                       min_samples_leaf=2, min_samples_split=14, n_estimators=100, \n",
        "                                                       random_state = 78329)),\n",
        "    StandardScaler(),\n",
        "    BernoulliNB(alpha=0.01, fit_prior=False)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7rpLWB6V3R"
      },
      "source": [
        "m2_scores = multi_score_cv(model = m2_eval, x = x, y = y, cv = cv, model_title = \"Recall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFJGAjFcRJRE"
      },
      "source": [
        "F1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2GUAEbbRKAk"
      },
      "source": [
        "m3 = make_pipeline(\n",
        "    ZeroCount(),\n",
        "    RandomForestClassifier(bootstrap=True, criterion=\"gini\", \n",
        "                           max_features=0.7500000000000001, min_samples_leaf=15, min_samples_split=13, n_estimators=100)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AqBBWfARv-J"
      },
      "source": [
        "m3_scores = multi_score_cv(model = m3_eval, x = x, y = y, cv = cv,\n",
        "                           model_title = \"F1\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}